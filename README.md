# üñêÔ∏è LibraSign

## ‚ÑπÔ∏è Introdu√ß√£o

O LibraSign √© um sistema de c√≥digo aberto desenvolvido como Trabalho de Conclus√£o de Curso que utiliza t√©cnicas de vis√£o computacional e aprendizado de m√°quina para reconhecer em tempo real os gestos correspondentes ao alfabeto manual da L√≠ngua Brasileira de Sinais. O projeto explora metodologias de processamento de dados geom√©tricos e classifica√ß√£o neural para aplica√ß√µes de acessibilidade comunicacional.

O sistema reconhece exclusivamente as configura√ß√µes de m√£o correspondentes √†s letras do alfabeto manual, de A a Z. Esta delimita√ß√£o foi estabelecida para permitir uma investiga√ß√£o acad√™mica focada na efic√°cia de redes neurais artificiais na classifica√ß√£o de gestos est√°ticos. O projeto destina-se primariamente ao ambiente acad√™mico e educacional, n√£o substituindo int√©rpretes profissionais ou servindo para uso comunicacional cotidiano em larga escala.

---

## üìö Fundamenta√ß√£o Acad√™mica

A fundamenta√ß√£o te√≥rica completa, incluindo revis√£o de literatura sobre l√≠nguas de sinais, t√©cnicas de vis√£o computacional, arquiteturas de redes neurais, metodologia experimental, an√°lise estat√≠stica dos resultados e discuss√£o sobre as implica√ß√µes sociais da tecnologia assistiva, encontra-se detalhada no documento acad√™mico completo dispon√≠vel neste reposit√≥rio: **[HeitorFernandes-TCC_BSI.pdf](https://github.com/Heitorccf/librasign/blob/master/HeitorFernandes-TCC_BSI.pdf)**.

O documento aborda a diferencia√ß√£o entre a comunica√ß√£o em l√≠nguas de sinais e a datilologia, as limita√ß√µes das abordagens baseadas em processamento de imagens brutas, a escolha por representa√ß√µes geom√©tricas de landmarks e as m√©tricas de desempenho obtidas atrav√©s de valida√ß√£o cruzada estratificada.

---

## üî≠ Vis√£o Geral do Sistema

### üöß Escopo e Limita√ß√µes

O sistema foi desenvolvido especificamente para reconhecer as configura√ß√µes de m√£o est√°ticas do alfabeto manual da Libras. Esta escolha metodol√≥gica foi deliberada e alinha-se com os objetivos de pesquisa do projeto.

O sistema reconhece as configura√ß√µes de m√£o correspondentes a cada uma das letras de A a Z quando apresentadas de forma est√°tica e isolada diante da c√¢mera. N√£o reconhece palavras completas em Libras, sinais compostos ou ideogr√°ficos, express√µes faciais, movimento corporal, utiliza√ß√£o do espa√ßo de sinaliza√ß√£o, varia√ß√µes regionais ou transi√ß√µes din√¢micas entre letras.

---

## üèóÔ∏è Arquitetura do Sistema

A arquitetura compreende tr√™s m√≥dulos principais:

1.  **M√≥dulo de Captura:** Utiliza a biblioteca MediaPipe do Google para acessar a c√¢mera e realizar a detec√ß√£o em tempo real das m√£os. Para cada frame capturado, o MediaPipe identifica vinte e um pontos de refer√™ncia anat√¥micos na m√£o detectada, extraindo suas coordenadas tridimensionais no espa√ßo normalizado. Estes dados geom√©tricos s√£o persistidos em arquivos CSV organizados por classe.

2.  **M√≥dulo de Treinamento:** Implementa o pipeline completo de aprendizado supervisionado. Ap√≥s carregar o dataset de landmarks, aplica transforma√ß√£o de normaliza√ß√£o geom√©trica que torna os dados invariantes √† posi√ß√£o absoluta da m√£o e √† escala. Os dados s√£o ent√£o padronizados utilizando `StandardScaler`. O modelo escolhido √© um Perceptron Multicamadas com duas camadas ocultas contendo 128 e 64 neur√¥nios, treinado atrav√©s do algoritmo de retropropaga√ß√£o. A avalia√ß√£o do desempenho √© conduzida atrav√©s de valida√ß√£o cruzada estratificada com cinco parti√ß√µes.

3.  **M√≥dulo de Predi√ß√£o:** Carrega os artefatos persistidos, inicializa a captura de v√≠deo e processa cada frame. Para cada detec√ß√£o de m√£o, as coordenadas dos landmarks s√£o extra√≠das, normalizadas e padronizadas exatamente da mesma forma que durante o treinamento. O sistema implementa filtro de vota√ß√£o majorit√°ria sobre os √∫ltimos dez frames e mecanismo de confirma√ß√£o temporal que exige que uma letra permane√ßa est√°vel por dois segundos antes de ser adicionada √† frase em constru√ß√£o.

---

## üîÑ Fluxo de Processamento

O sistema captura continuamente frames da c√¢mera do dispositivo. Cada frame √© processado pelo modelo de detec√ß√£o de m√£os do MediaPipe, que identifica a presen√ßa e localiza√ß√£o de m√£os na imagem. O MediaPipe identifica vinte e um pontos anat√¥micos na m√£o detectada, cada landmark representado por suas coordenadas tridimensionais.

Os landmarks brutos s√£o transformados atrav√©s de normaliza√ß√£o geom√©trica, com todos os pontos transladados para que o pulso fique na origem e escalonados pela dist√¢ncia entre o pulso e a base do dedo m√©dio. Os dados normalizados s√£o ent√£o padronizados utilizando o `StandardScaler` treinado. O vetor de caracter√≠sticas padronizado √© propagado atrav√©s das camadas do Perceptron Multicamadas, com a camada de sa√≠da produzindo probabilidades para cada classe.

Para reduzir oscila√ß√µes, o sistema aplica filtro de vota√ß√£o majorit√°ria sobre as √∫ltimas dez predi√ß√µes. Uma letra s√≥ √© confirmada se permanecer como predi√ß√£o predominante por dois segundos consecutivos. O sistema renderiza sobre o v√≠deo os landmarks detectados, a letra reconhecida, uma barra de progresso para confirma√ß√£o e, na parte inferior, a senten√ßa formada pelas letras confirmadas.

---

## üíª Requisitos do Sistema

### üíø Requisitos de Software

O sistema foi desenvolvido e testado em ambientes Linux, macOS e Windows. √â necess√°ria a instala√ß√£o do Python na vers√£o **3.11.13**. Vers√µes anteriores √† 3.9 n√£o s√£o suportadas. O sistema requer acesso a uma c√¢mera funcional para captura de v√≠deo em tempo real.

As bibliotecas essenciais e suas vers√µes s√£o:
* `scikit-learn==1.7.2`
* `numpy==2.2.6`
* `pandas==2.3.2`
* `opencv-python==4.12.0.88`
* `mediapipe==0.10.14`
* `kagglehub==0.3.13`

### üñ•Ô∏è Requisitos de Hardware

Recomenda-se um processador com pelo menos dois n√∫cleos f√≠sicos operando a dois gigahertz ou superior. Um m√≠nimo de quatro gigabytes de mem√≥ria RAM √© necess√°rio, sendo recomendados oito gigabytes ou mais. O projeto e o dataset p√∫blico ocupam menos de cem megabytes, recomendando-se ter pelo menos um gigabyte de espa√ßo livre.

A c√¢mera deve ter resolu√ß√£o m√≠nima de 640x480 pixels e taxa de captura de pelo menos 15 frames por segundo. C√¢meras com resolu√ß√£o HD ou superior com 30 frames por segundo proporcionam melhor experi√™ncia. Condi√ß√µes adequadas de ilumina√ß√£o s√£o cruciais, recomendando-se ambiente bem iluminado, evitando contraluz intenso ou sombras fortes.

---

## üì• Guia de Instala√ß√£o

### 1Ô∏è‚É£ Prepara√ß√£o do Ambiente

Verifique a instala√ß√£o do Python executando no terminal o comando:

```bash
python --version
````

Ou:

```bash
python3 --version
```

O comando deve retornar uma vers√£o 3.11.x. Se o comando n√£o for reconhecido ou a vers√£o for inferior, instale ou atualize o Python seguindo as instru√ß√µes espec√≠ficas para seu sistema operacional.

No Linux Debian ou Ubuntu, utilize:

```bash
sudo apt update
sudo apt install python3.11 python3.11-venv python3-pip
```

No macOS com Homebrew, execute:

```bash
brew install python@3.11
```

No Windows, baixe o instalador oficial do python.org, marcando a op√ß√£o de adicionar o Python ao PATH durante a instala√ß√£o.

### 2Ô∏è‚É£ Clonagem do Reposit√≥rio

Com o Python instalado, obtenha uma c√≥pia local do reposit√≥rio. Certifique-se de ter o Git instalado verificando com:

```bash
git --version
```

Navegue at√© o diret√≥rio onde deseja armazenar o projeto e execute:

```bash
git clone [https://github.com/heitorccf/librasign.git](https://github.com/heitorccf/librasign.git)
```

Entre no diret√≥rio rec√©m-criado com:

```bash
cd librasign
```

Todos os comandos subsequentes devem ser executados a partir desta pasta.

### 3Ô∏è‚É£ Configura√ß√£o do Ambiente Virtual

O uso de ambiente virtual √© recomendado para isolar as depend√™ncias do projeto.

No Linux e macOS, execute:

```bash
python3 -m venv .venv
```

No Windows, execute:

```bash
python -m venv .venv
```

Para ativar o ambiente virtual, no Linux e macOS execute:

```bash
source .venv/bin/activate
```

No Windows com Prompt de Comando, execute:

```bash
.venv\Scripts\activate.bat
```

No Windows com PowerShell, execute:

```bash
.venv\Scripts\Activate.ps1
```

No PowerShell, talvez seja necess√°rio ajustar a pol√≠tica de execu√ß√£o com:

```bash
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
```

Ap√≥s a ativa√ß√£o, seu terminal deve exibir o prefixo `(.venv)` no in√≠cio do prompt.

### 4Ô∏è‚É£ Instala√ß√£o das Depend√™ncias

Com o ambiente virtual ativado, atualize o pip com:

```bash
python -m pip install --upgrade pip
```

Instale as bibliotecas listadas no `requirements.txt` executando:

```bash
pip install -r requirements.txt
```

O pip instalar√° todas as bibliotecas necess√°rias, incluindo opencv-python, mediapipe, scikit-learn e kagglehub.

Teste se as bibliotecas principais foram instaladas executando:

```bash
python -c "import cv2, mediapipe, sklearn, numpy, pandas; print('Todas as bibliotecas foram importadas com sucesso')"
```

Se a mensagem de sucesso for exibida, o ambiente est√° pronto.

-----

## üöÄ Execu√ß√£o do Sistema

### ‚ñ∂Ô∏è Modo de Uso Padr√£o

Este modo utiliza o modelo pr√©-treinado dispon√≠vel na pasta models para reconhecimento em tempo real. Com o ambiente virtual ativado, execute:

```bash
python src/predict.py
```

O sistema carregar√° o modelo e abrir√° uma janela gr√°fica exibindo o v√≠deo da c√¢mera.

Posicione sua m√£o no campo de vis√£o da c√¢mera contra um fundo relativamente uniforme. Forme a configura√ß√£o de m√£o correspondente a uma letra do alfabeto manual e mantenha a posi√ß√£o est√°vel. Uma barra de progresso verde indicar√° o tempo para confirma√ß√£o do gesto. Ap√≥s dois segundos, a letra ser√° confirmada e adicionada √† frase na parte inferior da tela.

Os controles do teclado s√£o:

  * Tecla **ESC** para encerrar a aplica√ß√£o.
  * **Backspace** para remover a √∫ltima letra adicionada √† frase.
  * Tecla **C** para limpar completamente a frase.

### üì∑ Captura de Novo Dataset

Usu√°rios que desejam capturar seus pr√≥prios dados podem usar o script de captura executando:

```bash
python src/capture.py
```

O sistema abrir√° uma janela de v√≠deo e aguardar√° comandos.

Pressione a tecla da letra que deseja capturar. A captura iniciar√° automaticamente quando uma m√£o for detectada. Forme o gesto da letra escolhida e mova levemente a m√£o para criar variabilidade nos dados. O sistema capturar√° at√© mil amostras por letra, salvando os landmarks no diret√≥rio `data/landmarks` em arquivos CSV.

Os controles durante a captura s√£o:

  * Teclas **A a Z** para iniciar ou alternar a captura.
  * Tecla **zero** para capturar amostras da classe "nenhum".
  * Tecla **espa√ßo** para pausar ou retomar a captura.
  * Tecla **ESC** para encerrar o script.

### ‚öôÔ∏è Retreinamento do Modelo

Ap√≥s capturar um dataset personalizado, execute:

```bash
python src/train.py
```

O script baixar√° o dataset p√∫blico de refer√™ncia do Kaggle, carregar√° todos os arquivos CSV do diret√≥rio de landmarks, aplicar√° a normaliza√ß√£o geom√©trica e a padroniza√ß√£o, executar√° a valida√ß√£o cruzada estratificada com cinco parti√ß√µes para avaliar o modelo, exibir√° a acur√°cia m√©dia e o desvio padr√£o, treinar√° um modelo final usando todos os dados e salvar√° os novos artefatos no diret√≥rio `models`.

-----

## üìä Dataset P√∫blico

O dataset de landmarks usado no desenvolvimento do LibraSign foi disponibilizado publicamente na plataforma Kaggle. Ele cont√©m aproximadamente mil amostras para cada uma das vinte e sete classes, totalizando cerca de vinte e sete mil exemplos. O dataset pode ser acessado atrav√©s do link:

üîó [https://www.kaggle.com/datasets/heitorccf/librasign](https://www.kaggle.com/datasets/heitorccf/librasign)

O dataset consiste em arquivos CSV, um para cada classe, onde cada linha representa uma amostra contendo sessenta e tr√™s valores num√©ricos correspondentes √†s coordenadas x, y e z dos vinte e um landmarks da m√£o. Pesquisadores e desenvolvedores podem utilizar este dataset para reproduzir os resultados apresentados no trabalho, explorar diferentes arquiteturas de redes neurais, desenvolver outros sistemas de reconhecimento de gestos baseados em landmarks ou expandir o sistema com classes adicionais.

-----

## üõ†Ô∏è Solu√ß√£o de Problemas

  * Se o comando `python` n√£o for reconhecido ou exibir vers√£o 2.x, use `python3` em vez de python para todos os comandos.

  * Se o sistema falhar ao acessar a webcam, verifique as permiss√µes de privacidade do sistema operacional para permitir acesso √† c√¢mera.

  * Se o Python n√£o encontrar bibliotecas como `cv2` ou `mediapipe`, verifique se o ambiente virtual est√° ativado observando o prefixo `(.venv)` no terminal. Se n√£o estiver ativado, execute o comando de ativa√ß√£o apropriado e reinstale as depend√™ncias com:

<!-- end list -->

```bash
pip install -r requirements.txt
```

  * Se os landmarks da m√£o n√£o aparecerem ou piscarem na tela, melhore a ilumina√ß√£o do ambiente, use um fundo simples e de cor uniforme e ajuste a dist√¢ncia da m√£o para a c√¢mera entre trinta e sessenta cent√≠metros.

  * Se o sistema confundir letras frequentemente, revise o dataset personalizado garantindo que os gestos est√£o corretos e capture mais amostras com variabilidade. A confus√£o entre pares geometricamente semelhantes como M e N, G e Q, ou F e T √© uma limita√ß√£o conhecida do modelo atual.

-----

## üåç Aplicabilidade e Extensibilidade

Embora o LibraSign seja focado no alfabeto manual da Libras, sua arquitetura baseada em landmarks geom√©tricos oferece flexibilidade para adapta√ß√£o. A estrutura pode ser retreinada para reconhecer alfabetos manuais de outras l√≠nguas de sinais. O processo requer apenas a captura de um novo dataset com as configura√ß√µes de m√£o da l√≠ngua-alvo e o retreinamento do modelo.

O sistema pode ser expandido para reconhecer sinais ideogr√°ficos, o que exigiria a coleta de amostras desses sinais e, possivelmente, a mudan√ßa para arquiteturas de rede capazes de modelar sequ√™ncias temporais, j√° que muitos sinais envolvem movimento din√¢mico. A metodologia pode ser aplicada para reconhecer conjuntos de gestos personalizados para outros fins, como controle de interfaces ou comandos em realidade virtual. O LibraSign serve tamb√©m como ferramenta did√°tica para o ensino de conceitos de aprendizado de m√°quina, vis√£o computacional e processamento de sinais.

-----

## üìù Considera√ß√µes Finais

O LibraSign demonstra a viabilidade de abordagens baseadas em landmarks geom√©tricos para a classifica√ß√£o de gestos manuais. O projeto foi desenvolvido com aten√ß√£o √† reprodutibilidade, disponibilizando o c√≥digo e o dataset publicamente.

√â essencial reiterar que o sistema, em seu estado atual, possui limita√ß√µes que o posicionam como ferramenta de pesquisa e educa√ß√£o, n√£o como substituto para interpreta√ß√£o profissional. A Libras √© um sistema lingu√≠stico completo que transcende a soletra√ß√£o manual, envolvendo gram√°tica espacial, express√µes faciais e movimento corporal. O reconhecimento do alfabeto manual representa apenas uma pequena fra√ß√£o da comunica√ß√£o em Libras.

Portanto, o LibraSign deve ser visto como um primeiro passo metodol√≥gico em dire√ß√£o a sistemas mais completos e como ferramenta para o estudo de t√©cnicas de reconhecimento de padr√µes visuais. Usu√°rios interessados no entendimento t√©cnico aprofundado do sistema s√£o encorajados a consultar o documento acad√™mico completo.

-----

## üîó Refer√™ncias e Documenta√ß√£o Complementar

O trabalho de conclus√£o de curso completo est√° dispon√≠vel no arquivo **[HeitorFernandes-TCC\_BSI.pdf](https://github.com/Heitorccf/librasign/blob/master/HeitorFernandes-TCC_BSI.pdf)**. Este documento apresenta de forma detalhada todos os aspectos do projeto, incluindo revis√£o bibliogr√°fica sobre l√≠nguas de sinais e tecnologias assistivas, discuss√£o sobre abordagens metodol√≥gicas para processamento de sinais visuais, fundamenta√ß√£o te√≥rica sobre redes neurais, descri√ß√£o do processo de coleta e prepara√ß√£o do dataset, an√°lise estat√≠stica dos resultados experimentais e discuss√£o sobre limita√ß√µes do sistema e trabalhos futuros.

Para usu√°rios interessados em compreender mais profundamente as tecnologias empregadas, recomenda-se a consulta da documenta√ß√£o oficial das principais bibliotecas: MediaPipe, scikit-learn, OpenCV, NumPy e Pandas. Para aqueles interessados em aprender mais sobre a L√≠ngua Brasileira de Sinais, sugere-se consultar o Instituto Nacional de Educa√ß√£o de Surdos e a Federa√ß√£o Nacional de Educa√ß√£o e Integra√ß√£o dos Surdos.

O LibraSign √© um projeto de c√≥digo aberto e contribui√ß√µes da comunidade s√£o bem-vindas atrav√©s do reposit√≥rio no GitHub. O desenvolvimento foi poss√≠vel gra√ßas ao apoio institucional, √† orienta√ß√£o acad√™mica e √† disponibiliza√ß√£o gratuita de bibliotecas de c√≥digo aberto pela comunidade. Este projeto √© distribu√≠do sob a licen√ßa GNU General Public License v3.0.

<br>

**Reposit√≥rio:** [https://github.com/heitorccf/librasign](https://github.com/heitorccf/librasign)

**Dataset P√∫blico:** [https://www.kaggle.com/datasets/heitorccf/librasign](https://www.kaggle.com/datasets/heitorccf/librasign)

**Autor:** Heitor C√¢mara Costa Fernandes

**Institui√ß√£o:** Instituto Federal de Educa√ß√£o, Ci√™ncia e Tecnologia de S√£o Paulo (IFSP)

**Curso:** Bacharelado em Sistemas de Informa√ß√£o

**Contato:** [heitorccfernandes550@gmail.com](mailto:heitorccfernandes550@gmail.com) | [heitorccf2004@gmail.com](mailto:heitorccf2004@gmail.com)

**√öltima Atualiza√ß√£o:** Novembro de 2025
